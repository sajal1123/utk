{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import pickle\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKFileHandler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_attribute_dict(self, data: json) -> dict:\n",
    "        '''\n",
    "        Takes a json file and list of attributes and returns dictionary of grouped attributes in the json.\n",
    "        data: json\n",
    "        attributes: list [coordinates, indices, ids, normals, orientedEnvelope, sectionFootprint]\n",
    "        '''\n",
    "\n",
    "        # print(\"JDGBNDGJngdnD\")\n",
    "        # print(f'data-> {data}')\n",
    "        attr_dict = {\"coordinates\":[], \"indices\":[], \"normals\":[], \"ids\":[], \"orientedEnvelope\":[], \"sectionFootprint\":[], \"discardFuncInterval\": []}\n",
    "        for point in data['data']:\n",
    "            for k, v in point['geometry'].items():\n",
    "                if k == \"orientedEnvelope\" or k == \"sectionFootprint\":\n",
    "                    attr_dict[k].append(len(v))\n",
    "                for val in v:\n",
    "                    if k == \"orientedEnvelope\" or k == \"sectionFootprint\":\n",
    "                        attr_dict[k].append(len(val))\n",
    "                        for val_val in val:\n",
    "                            attr_dict[k].append(float(val_val))\n",
    "                    else:\n",
    "                        attr_dict[k].append(val)\n",
    "        return attr_dict\n",
    "    \n",
    "    def create_utk_binary(self, attribute_dict: dict, df: json, utk_filename: str, filepath: str) -> None:\n",
    "        '''\n",
    "        Given a json and attribute dictionary, it generates a .utk file with compressed attribute data\n",
    "        attribute_dict: attribute dictionary(created from create_attribute_dict)\n",
    "        df: json\n",
    "        utk_filename: desired output file name\n",
    "        '''\n",
    "\n",
    "        # print(f'attr dict = {attribute_dict.keys()}')\n",
    "        # print(f'df = {df.keys()}')\n",
    "        _id = df['id']\n",
    "        type_of_layer = df['type']\n",
    "        render_style = df['renderStyle']\n",
    "        style_key = df['styleKey']\n",
    "        if 'visible' in df.keys(): visible = df['visible']\n",
    "        if 'selectable' in df.keys(): selectable = df['selectable']\n",
    "        if 'skip' in df.keys(): skip = df['skip']\n",
    "\n",
    "\n",
    "        coordinates = attribute_dict['coordinates']\n",
    "        indices = attribute_dict['indices']\n",
    "        normals = attribute_dict['normals']\n",
    "        ids = attribute_dict['ids']\n",
    "        discardFuncInterval = attribute_dict['discardFuncInterval']\n",
    "        orientedEnvelope = attribute_dict['orientedEnvelope']\n",
    "        sectionFootprint = attribute_dict['sectionFootprint']\n",
    "        \n",
    "\n",
    "        packed_coordinates = struct.pack(f'{len(coordinates)}i', *coordinates)\n",
    "        packed_indices = struct.pack(f'{len(indices)}i', *indices)\n",
    "        packed_normals = struct.pack(f'{len(normals)}i', *normals)\n",
    "        packed_ids = struct.pack(f'{len(ids)}i', *ids)\n",
    "        packed_discardFuncInterval = struct.pack(f'{len(discardFuncInterval)}d', *discardFuncInterval)\n",
    "\n",
    "\n",
    "        packed_orientedEnvelope = b''\n",
    "        packed_orientedEnvelope_size = 0\n",
    "        for oEnvelope in orientedEnvelope:\n",
    "            if type(oEnvelope) == int:\n",
    "                packed_orientedEnvelope += struct.pack('d', float(oEnvelope))\n",
    "                packed_orientedEnvelope_size += 8\n",
    "            elif type(oEnvelope) == float:\n",
    "                packed_orientedEnvelope += struct.pack('d', oEnvelope)\n",
    "                packed_orientedEnvelope_size += 8\n",
    "        \n",
    "        packed_sectionFootprint = b''\n",
    "        packed_sectionFootprint_size = 0\n",
    "        for footprint in sectionFootprint:\n",
    "            if type(footprint) == int:\n",
    "                packed_sectionFootprint += struct.pack('d', float(footprint))\n",
    "                packed_sectionFootprint_size += 4\n",
    "            elif type(footprint) == float:\n",
    "                packed_sectionFootprint += struct.pack('d', footprint)\n",
    "                packed_sectionFootprint_size += 8\n",
    "        # packed_orientedEnvelope = pickle.dumps(orientedEnvelope)\n",
    "        # packed_sectionFootprint = pickle.dumps(sectionFootprint)\n",
    "\n",
    "        # calculate binary metadata size\n",
    "        binary_metadata_size = 0\n",
    "        for v in attribute_dict.values():\n",
    "            if len(v) > 0:\n",
    "                binary_metadata_size += 1\n",
    "        file_metadata_size = len(df.keys())-1\n",
    "\n",
    "        with open(os.path.join(filepath,utk_filename+'.utk'), 'w') as file:\n",
    "            file.write(f'{3 + file_metadata_size + binary_metadata_size}\\n')\n",
    "            file.write(f'file_metadata,{file_metadata_size}\\n')\n",
    "            file.write(f'id,{_id}\\n')\n",
    "            file.write(f'type,{type_of_layer}\\n')\n",
    "            file.write(f'renderStyle,{render_style}\\n')\n",
    "            file.write(f'styleKey,{style_key}\\n')\n",
    "            if 'visible' in df.keys(): file.write(f'visible,{visible}\\n')\n",
    "            if 'selectable' in df.keys(): file.write(f'selectable,{selectable}\\n')\n",
    "            if 'skip' in df.keys(): file.write(f'skip,{skip}\\n')\n",
    "            file.write(f'binary_metadata,{binary_metadata_size}\\n')\n",
    "            file.write(f'coordinates,{len(packed_coordinates)}\\n')\n",
    "            file.write(f'indices,{len(packed_indices)}\\n')\n",
    "            if len(normals) > 0: file.write(f'normals,{len(packed_normals)}\\n')\n",
    "            if len(ids) > 0: file.write(f'ids,{len(packed_ids)}\\n')\n",
    "            if len(discardFuncInterval) > 0: file.write(f'discardFuncInterval,{len(packed_discardFuncInterval)}\\n')\n",
    "            if len(orientedEnvelope) > 0: file.write(f'orientedEnvelope,{packed_orientedEnvelope_size}\\n')\n",
    "            if len(sectionFootprint) > 0: file.write(f'sectionFootprint,{packed_sectionFootprint_size}\\n')\n",
    "            file.write(\"BINARY DATA SEPARATOR\")\n",
    "        \n",
    "        with open(os.path.join(filepath,utk_filename+'.utk'), 'ab') as file:\n",
    "            file.write(packed_coordinates)\n",
    "            file.write(packed_indices)\n",
    "            if len(normals) > 0: file.write(packed_normals)\n",
    "            if len(ids) > 0: file.write(packed_ids)\n",
    "    \n",
    "        if len(orientedEnvelope) > 0 or len(sectionFootprint) > 0 or len(discardFuncInterval):\n",
    "            with open(os.path.join(filepath,utk_filename+'.utk'), 'a') as file:\n",
    "                file.write(\"FLOAT DATA BEGINS\")\n",
    "            with open(os.path.join(filepath,utk_filename+'.utk'), 'ab') as file:\n",
    "                if len(discardFuncInterval) > 0: file.write(packed_discardFuncInterval)\n",
    "                if len(orientedEnvelope) > 0: file.write(packed_orientedEnvelope)\n",
    "                if len(sectionFootprint) > 0: file.write(packed_sectionFootprint)\n",
    "\n",
    "        print(f\"Data has been written to file {utk_filename}\\n\")\n",
    "        \n",
    "    def read_utk_binary(self, filename: str, filepath: str) -> list:\n",
    "        '''\n",
    "        Parses a .utk file to retrieve data\n",
    "        '''\n",
    "        with open(os.path.join(filepath,filename+'.utk'), 'rb') as file:\n",
    "            file_size = int(file.readline().decode('utf-8').strip())\n",
    "\n",
    "            file_metadata_size = int(file.readline().decode('utf-8').strip().split(',')[1])\n",
    "\n",
    "            # Read metadata fields\n",
    "            metadata = {}\n",
    "            for _ in range(file_metadata_size):\n",
    "                field_name, field_value = file.readline().decode('utf-8').strip().split(',')\n",
    "                metadata[field_name] = field_value\n",
    "\n",
    "            # Read binary metadata\n",
    "            binary_metadata_size = int(file.readline().decode('utf-8').strip().split(',')[1])\n",
    "            binary_metadata = {}\n",
    "            for _ in range(binary_metadata_size):\n",
    "                field_name, field_size = file.readline().decode('utf-8').strip().split(',')\n",
    "                binary_metadata[field_name] = int(field_size)\n",
    "\n",
    "            data = {}\n",
    "            for field_name, field_size in binary_metadata.items():\n",
    "                if field_name in ['orientedEnvelope', 'sectionFootprint']:\n",
    "                    data[field_name] = pickle.loads(file.read(field_size))\n",
    "                elif field_name in [\"discardFuncInterval\"]:\n",
    "                    data[field_name] = struct.unpack(f'{field_size // struct.calcsize(\"d\")}d', file.read(field_size))\n",
    "                else:\n",
    "                    data[field_name] = struct.unpack(f'{field_size // struct.calcsize(\"i\")}i', file.read(field_size))\n",
    "\n",
    "            return metadata, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utk_handler = UTKFileHandler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file buildings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/buildings.json', 'r') as file:\n",
    "    df_buildings = json.load(file)\n",
    "attr_buildings = utk_handler.create_attribute_dict(df_buildings)\n",
    "utk_handler.create_utk_binary(attr_buildings, df_buildings, \"buildings\", './downtown_manhattan 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file parks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/parks.json', 'r') as file:\n",
    "    df_parks = json.load(file)\n",
    "attr_parks = utk_handler.create_attribute_dict(df_parks)\n",
    "utk_handler.create_utk_binary(attr_parks, df_parks, 'parks', './downtown_manhattan 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file roads\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/roads.json', 'r') as file:\n",
    "    df_roads = json.load(file)\n",
    "attr_roads = utk_handler.create_attribute_dict(df_roads)\n",
    "utk_handler.create_utk_binary(attr_roads, df_roads, 'roads', './downtown_manhattan 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file water\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/water.json', 'r') as file:\n",
    "    df_water = json.load(file)\n",
    "attr_water = utk_handler.create_attribute_dict(df_water)\n",
    "utk_handler.create_utk_binary(attr_water, df_water, 'water', './downtown_manhattan 2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file surface\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/surface.json', 'r') as file:\n",
    "    df_surface = json.load(file)\n",
    "attr_surface = utk_handler.create_attribute_dict(df_surface)\n",
    "utk_handler.create_utk_binary(attr_surface, df_surface, 'surface', './downtown_manhattan 2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Aug 24 2023, 15:09:45) [Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
